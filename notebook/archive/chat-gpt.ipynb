{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAIドキュメンテーション\n",
    "\n",
    "- [ドキュメンテーション | OpenAI](https://platform.openai.com/docs/introduction)\n",
    "  - [キーコンセプト](https://platform.openai.com/docs/introduction/key-concepts)\n",
    "  - [モデル一覧](https://platform.openai.com/docs/models/overview)\n",
    "  - [利用料金](https://openai.com/pricing)\n",
    "- [APIリファレンス | OpenAI](https://platform.openai.com/docs/api-reference)\n",
    "\n",
    "# 利用するコード\n",
    "\n",
    "- [Udemy講座「LangChainによる大規模言語モデル（LLM）アプリケーション開発入門」のコース前半のソースコード](https://colab.research.google.com/drive/14ToZc_fNM0WiwJRXWPhP929xQZ8xswd7?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIキーの発行\n",
    "\n",
    "- [API Keys | OpenAI](https://platform.openai.com/api-keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completions API\n",
    "\n",
    "- [Completions API リファレンス](https://platform.openai.com/docs/api-reference/completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-8oR32qojK7DppNL8JWBCGhl6rwnFs\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1707031064,\n",
      "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nHello! How can I assist you?\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 2,\n",
      "    \"completion_tokens\": 9,\n",
      "    \"total_tokens\": 11\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.openai.com/v1/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + openai_api_key\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo-instruct\",\n",
    "    \"prompt\": \"hello!\",\n",
    "    \"temperature\": 0,  # サンプリング温度(0~2) 0.8のような高い値は出力をよりランダムにし、0.2のような低い値は出力をより決定論的にします。\n",
    "}\n",
    "\n",
    "response = requests.post(url=url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-8oRE74U1R7YaClG2sbDMTpDyjLDib\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1707031751,\n",
      "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nHi there! How are you doing?\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"\\n\\nHello! How are you?\",\n",
      "      \"index\": 1,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 2,\n",
      "    \"completion_tokens\": 16,\n",
      "    \"total_tokens\": 18\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.openai.com/v1/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + openai_api_key\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo-instruct\",\n",
    "    \"prompt\": \"hello!\",\n",
    "    \"temperature\": 0.8,  # サンプリング温度(0~2) 0.8のような高い値は出力をよりランダムにし、0.2のような低い値は出力をより決定論的にします。\n",
    "    \"n\": 2, # 出力するテキストの数\n",
    "}\n",
    "\n",
    "response = requests.post(url=url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat API\n",
    "\n",
    "- [Chat Completions API ガイド](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)\n",
    "- [Chat API リファレンス](https://platform.openai.com/docs/api-reference/chat/create)\n",
    "\n",
    "## messagesパラメータ\n",
    "\n",
    "chatAPIでは `prompt` のかわりに `messages` というパラメータを利用する。\n",
    "\n",
    "### role\n",
    "\n",
    "会話は通常、 `system` メッセージでフォーマットされた後、 `user` と `assistant` のメッセージが交互に続く。\n",
    "\n",
    "- `user`  \n",
    "`assistant` が応答するためのリクエストを提供するロール。\n",
    "- `assistant`  \n",
    "`user` のメッセージに応答するロール。\n",
    "- `system`  \n",
    "性格やふるまいといった、`assistant` の挙動を設定するロール。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8oSxZeEYETxkU0rOo474r5jyeCddG\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1707038413,\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Hello! How can I assist you today?\"\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8,\n",
      "    \"completion_tokens\": 9,\n",
      "    \"total_tokens\": 17\n",
      "  },\n",
      "  \"system_fingerprint\": \"fp_69829325d0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + openai_api_key\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo-0125\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello\"\n",
    "      },\n",
    "    ],\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "response = requests.post(url=url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[キーコンセプト](https://platform.openai.com/docs/introduction/key-concepts)\n",
    "\n",
    "# トークンについて\n",
    "\n",
    "英単語ベースだと、1トークンは大体4文字(0.75語)。日本語は1文字1トークン。  \n",
    "入力と出力トークンがモデルの最大コンテキスト長を超えないようにしなければならない。  \n",
    "[Tokenizer Tool](https://platform.openai.com/tokenizer)でトークン数をチェックできる。\n",
    "\n",
    "- [GPT-3.5 Turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo)\n",
    "  - gpt-3.5-turbo-0125: 16385token\n",
    "  - gpt-3.5-turbo: 4096tokens\n",
    "  - gpt-3.5-turbo-1106: 16385token\n",
    "  - gpt-3.5-turbo-instruct: 4096tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# プロンプトエンジニアリング\n",
    "\n",
    "プロンプトを工夫することで、意図した回答を得やすくすること。\n",
    "\n",
    "- [Prompt Engineering Guide (日本語)](https://www.promptingguide.ai/jp)\n",
    "- [Prompt engineering | OpenAI](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "- [Best practices for prompt engineering with OpenAI API](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)\n",
    "\n",
    "## # プロンプトの要素\n",
    "\n",
    "[プロンプトの要素](https://www.promptingguide.ai/jp/introduction/elements)\n",
    "\n",
    "プロンプトには以下のようなコンポーネントが含まれ、異なる要素は `\"\"\"` や `###` といった記号で明確に分けることが推奨されている。  \n",
    "\n",
    "- 命令 - モデルに実行してほしい特定のタスクまたは命令\n",
    "- 文脈 - 外部情報や追加の文脈が含まれる場合があり、モデルをより良い応答に導くことができます。\n",
    "- 入力データ - 応答を見つけたい入力または質問\n",
    "- 出力指示子 - 出力のタイプや形式を示します。\n",
    "\n",
    "\n",
    "### 入力データ\n",
    "\n",
    "ユーザーからの入力を埋め込む。  \n",
    "\n",
    "\n",
    "> 以下の料理のレシピを教えてください  \n",
    ">\n",
    "> 料理名: \"\"\"  \n",
    "> カレー  \n",
    "> \"\"\"  \n",
    "\n",
    "\n",
    "### コンテキスト\n",
    "\n",
    "前提条件や外部情報などをコンテキストとして与えると文脈に沿った回答を得やすくなる  \n",
    "\n",
    "\n",
    "> 以下の料理のレシピを教えてください  \n",
    "> \n",
    "> context: \"\"\"  \n",
    "> 一人暮らし向けのレシピ生成サービスで使うので、分量は1人前にしてください。  \n",
    "> \"\"\"  \n",
    "> \n",
    "> 料理名: \"\"\"  \n",
    "> カレー  \n",
    "> \"\"\"  \n",
    "\n",
    "\n",
    "## # 有名な手法\n",
    "\n",
    "### Few-shotプロンプティング\n",
    "\n",
    "- [Few-Shotプロンプティング | Prompt Engineering Guide(日本語)](https://www.promptingguide.ai/jp/techniques/fewshot)\n",
    "\n",
    "プロンプトでいくつかデモンストレーションを与えることで意図する回答を得やすくする手法。\n",
    "\n",
    "\n",
    "> Q: りんごの色は？  \n",
    "> A: 赤  \n",
    "> Q: メロンの色は?  \n",
    "> A: 緑  \n",
    "> Q: バナナの色は?  \n",
    "> A:  \n",
    "\n",
    "> 黄色\n",
    "\n",
    "\n",
    "\n",
    "### Zero-shot COT プロンプティング\n",
    "\n",
    "- [Zero-shot COT プロンプティング | Prompt Engineering Guide(日本語)](https://www.promptingguide.ai/jp/techniques/cot#zero-shot-cot-prompting)\n",
    "\n",
    "COT とは chain-of-thoughtの略で、中間的な推論ステップを介して複雑な推論を可能にする手法。  \n",
    "`ステップバイステップで考えてみましょう。` という文言を追加すると、推論が必要なより複雑なタスクでより良い結果を得ることができる。\n",
    "\n",
    "> 私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？  \n",
    "> ステップバイステップで考えてみましょう。  \n",
    "\n",
    "> 最初に、10個のリンゴから始めました。  \n",
    "> 隣人と修理工に合わせて、リンゴを2つずつ渡し、残りは6個になりました。  \n",
    "> 次に、5つのリンゴを買い、11個になりました。  \n",
    "> 最後に、1つのリンゴを食べたため、残りは10個になります。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
