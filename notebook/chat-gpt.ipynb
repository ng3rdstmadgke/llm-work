{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAIドキュメンテーション\n",
    "\n",
    "- [ドキュメンテーション | OpenAI](https://platform.openai.com/docs/introduction)\n",
    "  - [キーコンセプト](https://platform.openai.com/docs/introduction/key-concepts)\n",
    "  - [モデル一覧](https://platform.openai.com/docs/models/overview)\n",
    "  - [利用料金](https://openai.com/pricing)\n",
    "- [APIリファレンス | OpenAI](https://platform.openai.com/docs/api-reference)\n",
    "\n",
    "# 利用するコード\n",
    "\n",
    "- [Udemy講座「LangChainによる大規模言語モデル（LLM）アプリケーション開発入門」のコース前半のソースコード](https://colab.research.google.com/drive/14ToZc_fNM0WiwJRXWPhP929xQZ8xswd7?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIキーの発行\n",
    "\n",
    "- [API Keys | OpenAI](https://platform.openai.com/api-keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completions API\n",
    "\n",
    "- [Completions API リファレンス](https://platform.openai.com/docs/api-reference/completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-8oR32qojK7DppNL8JWBCGhl6rwnFs\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1707031064,\n",
      "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nHello! How can I assist you?\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 2,\n",
      "    \"completion_tokens\": 9,\n",
      "    \"total_tokens\": 11\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.openai.com/v1/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + openai_api_key\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo-instruct\",\n",
    "    \"prompt\": \"hello!\",\n",
    "    \"temperature\": 0,  # サンプリング温度(0~2) 0.8のような高い値は出力をよりランダムにし、0.2のような低い値は出力をより決定論的にします。\n",
    "}\n",
    "\n",
    "response = requests.post(url=url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-8oRE74U1R7YaClG2sbDMTpDyjLDib\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1707031751,\n",
      "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nHi there! How are you doing?\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"\\n\\nHello! How are you?\",\n",
      "      \"index\": 1,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 2,\n",
      "    \"completion_tokens\": 16,\n",
      "    \"total_tokens\": 18\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.openai.com/v1/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + openai_api_key\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo-instruct\",\n",
    "    \"prompt\": \"hello!\",\n",
    "    \"temperature\": 0.8,  # サンプリング温度(0~2) 0.8のような高い値は出力をよりランダムにし、0.2のような低い値は出力をより決定論的にします。\n",
    "    \"n\": 2, # 出力するテキストの数\n",
    "}\n",
    "\n",
    "response = requests.post(url=url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat API\n",
    "\n",
    "- [Chat Completions API ガイド](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)\n",
    "- [Chat API リファレンス](https://platform.openai.com/docs/api-reference/chat/create)\n",
    "\n",
    "## messagesパラメータ\n",
    "\n",
    "chatAPIでは `prompt` のかわりに `messages` というパラメータを利用する。\n",
    "\n",
    "### role\n",
    "\n",
    "会話は通常、 `system` メッセージでフォーマットされた後、 `user` と `assistant` のメッセージが交互に続く。\n",
    "\n",
    "- `user`  \n",
    "`assistant` が応答するためのリクエストを提供するロール。\n",
    "- `assistant`  \n",
    "`user` のメッセージに応答するロール。\n",
    "- `system`  \n",
    "性格やふるまいといった、`assistant` の挙動を設定するロール。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8oSxZeEYETxkU0rOo474r5jyeCddG\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1707038413,\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Hello! How can I assist you today?\"\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8,\n",
      "    \"completion_tokens\": 9,\n",
      "    \"total_tokens\": 17\n",
      "  },\n",
      "  \"system_fingerprint\": \"fp_69829325d0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + openai_api_key\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo-0125\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello\"\n",
    "      },\n",
    "    ],\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "response = requests.post(url=url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[キーコンセプト](https://platform.openai.com/docs/introduction/key-concepts)\n",
    "\n",
    "# トークンについて\n",
    "\n",
    "英単語ベースだと、1トークンは大体4文字(0.75語)。日本語は1文字1トークン。  \n",
    "入力と出力トークンがモデルの最大コンテキスト長を超えないようにしなければならない。  \n",
    "[Tokenizer Tool](https://platform.openai.com/tokenizer)でトークン数をチェックできる。\n",
    "\n",
    "- [GPT-3.5 Turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo)\n",
    "  - gpt-3.5-turbo-0125: 16385token\n",
    "  - gpt-3.5-turbo: 4096tokens\n",
    "  - gpt-3.5-turbo-1106: 16385token\n",
    "  - gpt-3.5-turbo-instruct: 4096tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
