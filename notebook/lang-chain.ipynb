{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ LangChain\n",
    "\n",
    "LLMのラッパー\n",
    "\n",
    "- [LangChain公式ドキュメント](https://python.langchain.com/docs/get_started/introduction)\n",
    "- [LangChain | GitHub](https://github.com/langchain-ai/langchain)\n",
    "\n",
    "## # モジュール\n",
    "\n",
    "- [Modules | LangChain](https://python.langchain.com/docs/modules/)\n",
    "  - [Model I/O](https://python.langchain.com/docs/modules/model_io/)\n",
    "  - [Prompts](https://python.langchain.com/docs/modules/model_io/prompts/)\n",
    "  - [Chains](https://python.langchain.com/docs/modules/chains)\n",
    "  - [Indexing](https://python.langchain.com/docs/modules/data_connection/indexing)\n",
    "  - [Memory](https://python.langchain.com/docs/modules/memory/)\n",
    "  - [Agents](https://python.langchain.com/docs/modules/agents/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ Get Started\n",
    "\n",
    "- [Get started | LangChain](https://python.langchain.com/docs/expression_language/get_started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt, model, output parserを利用した基本的な例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'どうして布団が被告になったのか知っていますか？\\n\\nそれは、布団が寝ている間に逃げ出したからです。布団には「寝逃げ」の罪が課せられました。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic} についてのジョークをおしえて\")\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"ふとん\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ Models モジュール\n",
    "\n",
    "LangChainで使用する機械学習のモデルのこと。以下の3種類がある。\n",
    "\n",
    "- LLMs  \n",
    "OpenAIのCompletions API(gpt-3.5-turbo-instructなど)の大規模言語モデル\n",
    "- Chat Models  \n",
    "OpenAIのChat API(gpt-4, gpt-3.5-turboなど)の大規模言語モデル\n",
    "- Text Embedding Models\n",
    "テキストをベクトル化するモデル。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs\n",
    "\n",
    "- [Modules - Model I/O - LLMS | LangChain公式](https://python.langchain.com/docs/modules/model_io/llms/)\n",
    "\n",
    "内部的にはCompletionsAPIが利用される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/home/vscode/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "私は、山田太郎と申します。東京都出身で、現在は大学生として都内の大学に通っています。趣味はスポーツ観戦や音楽鑑賞で、特にサッカーやロックバンドが好きです。将来の夢は、国際的な企業で働くことで、留学経験も積んで自分を磨きたいと思っています。また、人とのコミュニケーションを大切にし、常に新しいことに挑戦することで成長していきたいと考えています。よろしくお願いします。\n"
     ]
    }
   ],
   "source": [
    "# LLMs\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "result = llm.predict(\"自己紹介してください\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "- [Modules - Model I/O - Chat Models | LangChain公式](https://python.langchain.com/docs/modules/model_io/chat/)\n",
    "\n",
    "内部的には ChatAPIが利用される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/home/vscode/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はじめまして、私はAIアシスタントです。自然言語処理技術を用いて、様々な質問に回答したり、会話をすることができます。お手伝いが必要なことがあれば、遠慮なくお知らせください。どうぞよろしくお願いいたします。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "result = llm.predict(\"自己紹介してください\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ Prompts モジュール\n",
    "\n",
    "- [Modules - Model I/O - Prompts | LangChain公式](https://python.langchain.com/docs/modules/model_io/prompts/)\n",
    "\n",
    "モデルへの入力を組み立てるモジュール。以下の4つの要素がある。\n",
    "\n",
    "- Prompt Templetes  \n",
    "プロンプトをテンプレート化できる\n",
    "- Chat Prompt Templates\n",
    "- Example Selectors\n",
    "- Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "プロンプトをテンプレート化することができる。  \n",
    "あくまで文字列を編集するだけでAPIをコールするわけではない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "次のコマンドの概要を説明してください。\n",
      "\n",
      "コマンド: ls\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "次のコマンドの概要を説明してください。\n",
    "\n",
    "コマンド: {command}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template,\n",
    "  input_variables=[\"command\"],\n",
    ")\n",
    "result = prompt.format(command=\"ls\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ Chains モジュール\n",
    "\n",
    "- [Modules - Chains | LangChain公式](https://python.langchain.com/docs/modules/chains)\n",
    "\n",
    "chainsは、モジュール(Models, Templates, Chainsなど)を連結する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "次のコマンドの概要を説明してください。\n",
      "\n",
      "コマンド: ls\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "lsコマンドは、リスト（list）の略で、指定されたディレクトリ内のファイルやディレクトリの一覧を表示するコマンドです。デフォルトではカレントディレクトリの内容を表示しますが、任意のディレクトリを指定することもできます。lsコマンドを実行することで、ファイルやディレクトリの名前や属性、更新日時などの情報を確認することができます。\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "langchain.verbose = True\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "template = \"\"\"\n",
    "次のコマンドの概要を説明してください。\n",
    "\n",
    "コマンド: {command}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template,\n",
    "  input_variables=[\"command\"],\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "result = chain.run(\"ls\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain\n",
    "\n",
    "ChainとChainを直列に連結できる。\n",
    "\n",
    "<img src=\"./img/simple_sequential_chain.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "以下の質問に回答してください。\n",
      "\n",
      "### 質問 ###\n",
      "私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\n",
      "### 質問終了 ###\n",
      "\n",
      "ステップバイステップで考えましょう。\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m1. 最初に市場で10個のリンゴを買いました。\n",
      "2. 隣人に2つ、修理工に2つ渡しました。残りは10 - 2 - 2 = 6個です。\n",
      "3. その後、5つのリンゴを追加で購入しました。残りは6 + 5 = 11個です。\n",
      "4. 最後に1つのリンゴを食べたので、残りは11 - 1 = 10個です。\n",
      "\n",
      "したがって、最終的には10個のリンゴが残ります。\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "入力を結論だけ一言に要約してください。\n",
      "\n",
      "### 入力 ###\n",
      "1. 最初に市場で10個のリンゴを買いました。\n",
      "2. 隣人に2つ、修理工に2つ渡しました。残りは10 - 2 - 2 = 6個です。\n",
      "3. その後、5つのリンゴを追加で購入しました。残りは6 + 5 = 11個です。\n",
      "4. 最後に1つのリンゴを食べたので、残りは11 - 1 = 10個です。\n",
      "\n",
      "したがって、最終的には10個のリンゴが残ります。\n",
      "### 入力終了 ###\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m最終的には10個のリンゴが残ります。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "最終的には10個のリンゴが残ります。\n"
     ]
    }
   ],
   "source": [
    "# 「ステップバイステップで考える(COT)」 と 「要約」 の組み合わせ\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "langchain.verbose = True\n",
    "\n",
    "# 「ステップバイステップで考える(COT)」 Prompt と Chain を用意\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "cot_template = \"\"\"\n",
    "以下の質問に回答してください。\n",
    "\n",
    "### 質問 ###\n",
    "{question}\n",
    "### 質問終了 ###\n",
    "\n",
    "ステップバイステップで考えましょう。\n",
    "\"\"\"\n",
    "\n",
    "cot_prompt = PromptTemplate(\n",
    "  template=cot_template,\n",
    "  input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "cot_chain = LLMChain(llm=chat, prompt=cot_prompt)\n",
    "\n",
    "# 「要約」 Prompt と Chain を用意\n",
    "summarize_template = \"\"\"\n",
    "入力を結論だけ一言に要約してください。\n",
    "\n",
    "### 入力 ###\n",
    "{input}\n",
    "### 入力終了 ###\n",
    "\"\"\"\n",
    "\n",
    "summarize_prompt = PromptTemplate(\n",
    "  input_variables=[\"input\"],\n",
    "  template=summarize_template,\n",
    ")\n",
    "\n",
    "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)\n",
    "\n",
    "\n",
    "# 2 つの Chain を直列に繋ぐ\n",
    "cot_summarize_chain = SimpleSequentialChain(\n",
    "  chains=[cot_chain, summarize_chain]\n",
    ")\n",
    "\n",
    "# 実行\n",
    "result = cot_summarize_chain(\n",
    "  \"私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\"\n",
    ")\n",
    "\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ Output Parsers\n",
    "\n",
    "- [Modules - Model I/O - Output Parsers | LangChain](https://python.langchain.com/docs/modules/model_io/output_parsers/)\n",
    "\n",
    "LLMの応答を抽出して、Pythonオブジェクトにマッピングするといった機能を提供する。  \n",
    "他にもOutput Parserには、不正な形式でうまく解析できなかった場合に LLM に形式を整えてもらうような機能がある。  \n",
    "\n",
    "Promptsには他にも、Few-shotプロンプティングの例を埋め込むための「ExampleSelectors」という機能もある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'langchain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, validator\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m----> 8\u001b[0m \u001b[43mlangchain\u001b[49m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRecipe\u001b[39;00m(BaseModel):\n\u001b[1;32m     11\u001b[0m   ingredients: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m Field(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mingredients of the dish\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'langchain' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List\n",
    "\n",
    "langchain.verbose = True\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "  ingredients: List[str] = Field(description=\"ingredients of the dish\")\n",
    "  step: List[str] = Field(description=\"steps to cook the dish\")\n",
    "\n",
    "template = \"\"\"料理のレシピを教えてください。\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "料理名: {dish}\n",
    "\"\"\"\n",
    "\n",
    "# 出力値のフォーマットを指示するためのプロンプトを生成する\n",
    "parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template,\n",
    "  input_variables=[\"dish\"],\n",
    "  partial_variables={\n",
    "    \"format_instructions\": parser.get_format_instructions()\n",
    "  },\n",
    ")\n",
    "\n",
    "# Chain を実行\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "output = chain.run(dish=\"カレー\")\n",
    "print(\"=== === === output === === ===\")\n",
    "print(output)\n",
    "\n",
    "# 出力をPydanticオブジェクトにパース\n",
    "recipe = parser.parse(output)\n",
    "print(\"=== === === recipe === === ===\")\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
