{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ LangChain\n",
    "\n",
    "LLMのラッパー\n",
    "\n",
    "- [LangChain公式ドキュメント](https://python.langchain.com/docs/get_started/introduction)\n",
    "- [LangChain | GitHub](https://github.com/langchain-ai/langchain)\n",
    "- [Get started | LangChain](https://python.langchain.com/docs/expression_language/get_started)\n",
    "\n",
    "## # モジュール\n",
    "\n",
    "- [Modules | LangChain](https://python.langchain.com/docs/modules/)\n",
    "  - [Model I/O](https://python.langchain.com/docs/modules/model_io/)\n",
    "  - [Prompts](https://python.langchain.com/docs/modules/model_io/prompts/)\n",
    "  - [Chains](https://python.langchain.com/docs/modules/chains)\n",
    "  - [Indexing](https://python.langchain.com/docs/modules/data_connection/indexing)\n",
    "  - [Memory](https://python.langchain.com/docs/modules/memory/)\n",
    "  - [Agents](https://python.langchain.com/docs/modules/agents/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ Models モジュール\n",
    "\n",
    "LangChainで使用する機械学習のモデルのこと。以下の3種類がある。\n",
    "\n",
    "- LLMs  \n",
    "OpenAIのCompletions API(gpt-3.5-turbo-instructなど)の大規模言語モデル\n",
    "- Chat Models  \n",
    "OpenAIのChat API(gpt-4, gpt-3.5-turboなど)の大規模言語モデル\n",
    "- Text Embedding Models\n",
    "テキストをベクトル化するモデル。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs\n",
    "\n",
    "- [Modules - Model I/O - LLMS | LangChain公式](https://python.langchain.com/docs/modules/model_io/llms/)\n",
    "\n",
    "内部的にはCompletionsAPIが利用される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "私は、山田太郎と申します。東京都出身で、現在は大学生として都内の大学に通っています。趣味はスポーツ観戦や音楽鑑賞で、特にサッカーやロックバンドが好きです。将来の夢は、国際的な企業で働くことで、留学経験も積んで自分を磨きたいと思っています。また、人とのコミュニケーションを大切にし、常に新しいことに挑戦することで成長していきたいと考えています。よろしくお願いします。\n"
     ]
    }
   ],
   "source": [
    "# LLMs\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "result = llm.predict(\"自己紹介してください\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "- [Modules - Model I/O - Chat Models | LangChain公式](https://python.langchain.com/docs/modules/model_io/chat/)\n",
    "\n",
    "内部的には ChatAPIが利用される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はじめまして、私はAIアシスタントです。自然言語処理技術を用いて、様々な質問や会話に対応することができます。お手伝いが必要なことがあれば、遠慮なくお知らせください。どうぞよろしくお願いいたします。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "result = llm.predict(\"自己紹介してください\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ Prompts モジュール\n",
    "\n",
    "- [Modules - Model I/O - Prompts | LangChain公式](https://python.langchain.com/docs/modules/model_io/prompts/)\n",
    "\n",
    "モデルへの入力を組み立てるモジュール。以下の4つの要素がある。\n",
    "\n",
    "- Prompt Templetes  \n",
    "プロンプトをテンプレート化できる\n",
    "- Chat Prompt Templates\n",
    "- Example Selectors\n",
    "- Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "プロンプトをテンプレート化することができる。  \n",
    "あくまで文字列を編集するだけでAPIをコールするわけではない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "次のコマンドの概要を説明してください。\n",
      "\n",
      "コマンド: ls\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "次のコマンドの概要を説明してください。\n",
    "\n",
    "コマンド: {command}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template,\n",
    "  input_variables=[\"command\"],\n",
    ")\n",
    "result = prompt.format(command=\"ls\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ Chains モジュール\n",
    "\n",
    "- [Modules - Chains | LangChain公式](https://python.langchain.com/docs/modules/chains)\n",
    "\n",
    "chainsは、モジュール(Models, Templates, Chainsなど)を連結する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "次のコマンドの概要を説明してください。\n",
      "\n",
      "コマンド: ls\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "lsコマンドは、リスト（list）の略で、指定されたディレクトリ内のファイルやディレクトリの一覧を表示するためのコマンドです。デフォルトではカレントディレクトリの内容を表示しますが、任意のディレクトリを指定することもできます。lsコマンドを実行することで、ファイルやディレクトリの名前や属性、更新日時などの情報を確認することができます。\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "langchain.verbose = True\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "template = \"\"\"\n",
    "次のコマンドの概要を説明してください。\n",
    "\n",
    "コマンド: {command}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template,\n",
    "  input_variables=[\"command\"],\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "result = chain.run(\"ls\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain\n",
    "\n",
    "ChainとChainを直列に連結できる。\n",
    "\n",
    "<img src=\"./img/simple_sequential_chain.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "以下の質問に回答してください。\n",
      "\n",
      "### 質問 ###\n",
      "私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\n",
      "### 質問終了 ###\n",
      "\n",
      "ステップバイステップで考えましょう。\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m1. 最初に市場で10個のリンゴを買いました。\n",
      "2. 隣人に2つ、修理工に2つ渡しました。残りは10 - 2 - 2 = 6個です。\n",
      "3. その後、5つのリンゴを追加で購入しました。残りは6 + 5 = 11個です。\n",
      "4. 最後に1つのリンゴを食べました。残りは11 - 1 = 10個です。\n",
      "\n",
      "したがって、最終的には10個のリンゴが残ります。\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "入力を結論だけ一言に要約してください。\n",
      "\n",
      "### 入力 ###\n",
      "1. 最初に市場で10個のリンゴを買いました。\n",
      "2. 隣人に2つ、修理工に2つ渡しました。残りは10 - 2 - 2 = 6個です。\n",
      "3. その後、5つのリンゴを追加で購入しました。残りは6 + 5 = 11個です。\n",
      "4. 最後に1つのリンゴを食べました。残りは11 - 1 = 10個です。\n",
      "\n",
      "したがって、最終的には10個のリンゴが残ります。\n",
      "### 入力終了 ###\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m最終的には10個のリンゴが残ります。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "最終的には10個のリンゴが残ります。\n"
     ]
    }
   ],
   "source": [
    "# 「ステップバイステップで考える(COT)」 と 「要約」 の組み合わせ\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "langchain.verbose = True\n",
    "\n",
    "# 「ステップバイステップで考える(COT)」 Prompt と Chain を用意\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "cot_template = \"\"\"\n",
    "以下の質問に回答してください。\n",
    "\n",
    "### 質問 ###\n",
    "{question}\n",
    "### 質問終了 ###\n",
    "\n",
    "ステップバイステップで考えましょう。\n",
    "\"\"\"\n",
    "\n",
    "cot_prompt = PromptTemplate(\n",
    "  template=cot_template,\n",
    "  input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "cot_chain = LLMChain(llm=chat, prompt=cot_prompt)\n",
    "\n",
    "# 「要約」 Prompt と Chain を用意\n",
    "summarize_template = \"\"\"\n",
    "入力を結論だけ一言に要約してください。\n",
    "\n",
    "### 入力 ###\n",
    "{input}\n",
    "### 入力終了 ###\n",
    "\"\"\"\n",
    "\n",
    "summarize_prompt = PromptTemplate(\n",
    "  input_variables=[\"input\"],\n",
    "  template=summarize_template,\n",
    ")\n",
    "\n",
    "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)\n",
    "\n",
    "\n",
    "# 2 つの Chain を直列に繋ぐ\n",
    "cot_summarize_chain = SimpleSequentialChain(\n",
    "  chains=[cot_chain, summarize_chain]\n",
    ")\n",
    "\n",
    "# 実行\n",
    "result = cot_summarize_chain(\n",
    "  \"私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\"\n",
    ")\n",
    "\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ Output Parsers\n",
    "\n",
    "- [Modules - Model I/O - Output Parsers | LangChain](https://python.langchain.com/docs/modules/model_io/output_parsers/)\n",
    "\n",
    "LLMの応答を抽出して、Pythonオブジェクトにマッピングするといった機能を提供する。  \n",
    "他にもOutput Parserには、不正な形式でうまく解析できなかった場合に LLM に形式を整えてもらうような機能がある。  \n",
    "\n",
    "Promptsには他にも、Few-shotプロンプティングの例を埋め込むための「ExampleSelectors」という機能もある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m料理のレシピを教えてください。\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"step\": {\"description\": \"steps to cook the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Step\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"step\"]}\n",
      "```\n",
      "\n",
      "料理名: カレー\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "=== === === output === === ===\n",
      "```json\n",
      "{\n",
      "    \"ingredients\": [\n",
      "        \"玉ねぎ\",\n",
      "        \"人参\",\n",
      "        \"じゃがいも\",\n",
      "        \"牛肉\",\n",
      "        \"カレールー\",\n",
      "        \"水\"\n",
      "    ],\n",
      "    \"step\": [\n",
      "        \"1. 材料を準備する。\",\n",
      "        \"2. 玉ねぎ、人参、じゃがいもを切る。\",\n",
      "        \"3. 牛肉を炒める。\",\n",
      "        \"4. 野菜を加えて炒める。\",\n",
      "        \"5. 水を加えて煮込む。\",\n",
      "        \"6. カレールーを溶かして加える。\",\n",
      "        \"7. 全体を混ぜて完成する。\"\n",
      "    ]\n",
      "}\n",
      "```\n",
      "=== === === recipe === === ===\n",
      "ingredients=['玉ねぎ', '人参', 'じゃがいも', '牛肉', 'カレールー', '水'] step=['1. 材料を準備する。', '2. 玉ねぎ、人参、じゃがいもを切る。', '3. 牛肉を炒める。', '4. 野菜を加えて炒める。', '5. 水を加えて煮込む。', '6. カレールーを溶かして加える。', '7. 全体を混ぜて完成する。']\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List\n",
    "\n",
    "langchain.verbose = True\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "  ingredients: List[str] = Field(description=\"ingredients of the dish\")\n",
    "  step: List[str] = Field(description=\"steps to cook the dish\")\n",
    "\n",
    "template = \"\"\"料理のレシピを教えてください。\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "料理名: {dish}\n",
    "\"\"\"\n",
    "\n",
    "# 出力値のフォーマットを指示するためのプロンプトを生成する\n",
    "parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template,\n",
    "  input_variables=[\"dish\"],\n",
    "  partial_variables={\n",
    "    \"format_instructions\": parser.get_format_instructions()\n",
    "  },\n",
    ")\n",
    "\n",
    "# Chain を実行\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "output = chain.run(dish=\"カレー\")\n",
    "print(\"=== === === output === === ===\")\n",
    "print(output)\n",
    "\n",
    "# 出力をPydanticオブジェクトにパース\n",
    "recipe = parser.parse(output)\n",
    "print(\"=== === === recipe === === ===\")\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
